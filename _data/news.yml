#To add a new news item, please copy the form below, remove # characters and change the contents accordingly.
#It is important to preserve the exact same syntax and identation.
#The characters >- transform everything on the next line on a string, allowing us to escape : and - characters normaly, which otherwise are control characters on yml files.
#
#
#- date: October 13, 2017
#  headline: >-
#    SIG Asia and ICCV 2017 papers
#  text: >-
#    Op dit plein stond het hoofdkantoor van de NIROM: Nederlands Indische Radio Omroep
#  highlight: 1
#  image: news_1.PNG

- date: Aug 5, 2021
  headline: >-
    Talk by Tel-Aviv's PhD Candidates Or Patashnik and Yuval Alaluf
  text: >-
    <strong>Title:</strong> Recent Advancements in StyleGAN Inversion</p> <p style="text-align: justify;"><strong>Time:</strong> Wednesday, August 11, 10AM </p> <p style="text-align: justify;"><strong>Abstract:&nbsp;</strong>StyleGAN has recently been established as the state-of-the-art unconditional generator, synthesizing images of phenomenal realism and fidelity. With its rich semantic space, many works have attempted to understand and control StyleGAN&rsquo;s latent representations with the goal of performing image manipulations. To perform manipulations on real images, however, one must learn to &ldquo;invert&rdquo; the GAN and encode a given image into StyleGAN&rsquo;s latent space, which remains an open challenge. In this talk, we will discuss recent techniques and advancements in GAN Inversion and explore their importance for real image editing applications. In addition, going beyond the inversion task, we demonstrate how StyleGAN can be used for performing a wide range of image-to-image translation tasks.</p> <p style="text-align: justify;"><strong>Bios:&nbsp;</strong>Or and Yuval are both graduate students studying Computer Science at Tel-Aviv University under the supervision of Professor Daniel Cohen-Or and have collaborated on numerous works in the past year. Their main interests lie in the field of Computer Vision with recent work centered around image generation and manipulation.</p> <p style="text-align: center;"><a href="https://orpatashnik.github.io/">https://orpatashnik.github.io/</a></p> <p style="text-align: center;"><a href="https://yuval-alaluf.github.io/">https://yuval-alaluf.github.io/</a>
  highlight: 1
  image: telaviv_talk.JPG

- date: Jun 19, 2021
  headline: >-
    GrUVi making waves at CVPR 2021
  text: >-
    <span style="font-weight: 400;">CVPR, the premier conference on computer vision, will be held virtually this year (June 19-25). GrUVi lab will once again have an incredible showing at CVPR, with 16 technical papers, 2 invited talks, 4 co-organized workshops, and 1 hosted challenge!</span></p> <p><br /><br /></p> <p><strong>Workshop co-organization</strong></p> <p>&nbsp;</p> <p align="justify"><span style="font-weight: 400;">GrUViers will co-organize 4 workshops featuring state-of-the-art research and will host one challenge:</span></p> <p>&nbsp;</p> <ul align="justify"> <li style="font-weight: 400;"><a href="https://sites.google.com/view/cvpr2021-3d-vision-robotics"><span style="font-weight: 400;">3D Vision and Robotics</span></a><span style="font-weight: 400;"></span></li> <li style="font-weight: 400;"><a href="http://www.scan-net.org/cvpr2021workshop/"><span style="font-weight: 400;">ScanNet Indoor Scene Understanding Challenge</span></a><span style="font-weight: 400;"></span></li> <li style="font-weight: 400;"><a href="https://learn3dg.github.io/"><span style="font-weight: 400;">Learning to Generate 3D Shapes and Scenes</span></a><span style="font-weight: 400;"></span></li> <li style="font-weight: 400;"><a href="https://language3dscenes.github.io/"><span style="font-weight: 400;">Language for 3D Scenes</span></a><span style="font-weight: 400;"> </span></li><li style="font-weight: 400;"> <a href="http://multion-challenge.cs.sfu.ca/"><span style="font-weight: 400;">Multi-Object Navigation Challenge at the Embodied-AI workshop</span></a><span style="font-weight: 400;"> </span></li> </ul> <p><br /><br /></p> <p><strong>Invited workshop talks</strong></p> <p>&nbsp;</p> <p align="justify"><span style="font-weight: 400;">Yasutaka Furukawa will give a talk at the <a href="https://cv4aec.github.io/">&ldquo;Computer Vision in the Built Environment&rdquo;</a> workshop, while Manolis Savva will give a talk at the <a href="https://sites.google.com/view/cvpr2021-3d-vision-robotics">&ldquo;3D Vision and Robotics&rdquo;</a> workshop.</span></p> <p><br /><br /></p> <p><strong>Technical Papers and GrUVi authors</strong></p> <p>&nbsp;</p> <p align="justify"><span style="font-weight: 400;">Congratulations to all authors for the accepted papers! The full list of papers featured on CVPR 2021 can be accessed </span><a href="https://gruvi.cs.sfu.ca/publications/"><span style="font-weight: 400;">here</span></a>. 
  highlight: 1
  image: CVPR2021.jpeg

- date: April 23, 2021
  headline: >-
    Talk by Yang Wang
  text: >-
    <b>Talk title:</b> Self&ndash;Adaptive Visual Learning  <br><br><b>Time:</b> April 23, from 3:30 to 4:30PM (PST)  <br><br><b>Abstract:</b> There have been significant advances in computer vision in the past few years. Despite the success, current computer vision systems are still hard to use or deploy in many real-world scenarios. In particular, current computer vision systems usually learn a generic model. But in real world applications, a single generic model is often not powerful enough to handle the diverse scenarios. In this talk, I will introduce some of our recent work on self-adaptive visual learning. Instead of learning and deploying one generic model, our goal is to learn a model that can effectively adapt itself to different environments during testing. I will present applications from several computer visions, such as crowd counting, anomaly detection, personalized highlight detection, etc. <br><br><b>Bio:</b> <a target="_blank" href="https://www.cs.umanitoba.ca/~ywang/">Yang Wang</a> is an associate professor in the Department of Computer Science, <a target="_blank" href="https://sci.umanitoba.ca/cs/">University of Manitoba</a>. He is currently on leave and working as the Chief Scientist in Computer Vision, Noah&lsquo;s Ark Lab, Huawei Technologies Canada. He did his PhD from Simon Fraser University, MSc from University of Alberta, and BEng from Harbin Institute of Technology. Before joining UManitoba, he worked as a NSERC postdoc at the University of Illinois at Urbana-Champaign. His research focuses on computer vision and machine learning. He received the 2017 Falconer Emerging Researcher Rh Award in applied science at the University of Manitoba. He currently holds the inaugural Faculty of Science research chair in fundamental science at UManitoba.
  highlight: 1
  image: Yang_Wang.jpeg
  
- date: April 16, 2021
  headline: >-
    Talk by Unnat Jain
  text: >-
    <b>Talk title:</b> AI Agents that can Collaborate and Communicate in Virtual Visual Worlds  <br><br><b>Time:</b> April 16, from 3:30 to 4:30PM (PST)  <br><br><b>Abstract:</b> The past decade in artificial intelligence, particularly computer vision, has been about hammering passively collected datasets with massive deep learning models. As the race to boost metrics on them is saturating, researchers like me are working on visual or embodied AI agents that draw inspiration from how toddlers acquire intelligence, i.e., by exploring, interacting, and navigating in their environments.<br>Particularly, I am excited to study how visual embodied agents can learn key skills of social intelligence – collaboration and communication. In this talk, I’ll discuss how we are building AI Agents that can collaborate and communicate in virtual visual worlds. Moreover, I’ll discuss how simplistic gridworlds and visual worlds can be connected with a ‘GridToPix’ methodology. The relevant papers can be found on my <a target="_blank" href="https://unnat.github.io/">webpage</a>. <br><br><b>Bio:</b> <a target="_blank" href="https://unnat.github.io/">Unnat Jain</a> is a Ph.D. student in Computer Science at <a target="_blank" href="https://cs.illinois.edu/">UIUC</a> working with Alex Schwing and Svetlana Lazebnik. His research is focused on developing collaborative and communicative visual agents. He has worked as a research intern at DeepMind, Facebook AI Research, and Allen Institute for AI. He has won many awards including the Director’s Gold Medal (IIT Kanpur), Cadence Gold Medal for best engineering thesis (IIT Kanpur), David J. Kuck Outstanding MS Thesis Award (UIUC), Siebel Scholars, and was a finalist of Qualcomm Innovation Fellowship 2019.
  highlight: 1
  image: Unnat_Jain.jpeg

- date: April 9, 2021
  headline: >-
    Talk by Kwang Moo Yi
  text: >-
    <b>Talk title:</b> Towards Machines that Understand Geometry  <br><br><b>Time:</b> April 9, from 3:30 to 4:30PM (PST)  <br><br><b>Abstract:</b> Understanding the how the worlds looks like and interacting with the environment is a core ability of an intelligent being. Naturally, it has been a long-lasting research topic in Computer Vision. The capacity of machines in figuring out surrounding geometry has increased dramatically over the last decade, so much so that self-driving cars and autonomous drones are not a distant future. However, the “last mile” has shown to be more difficult than anticipated, delaying the arrival of these machines. Machine learning, like many other applications, have very recently started to help in this regard, again creating a leap from what it could do just a couple years back.<br>In this talk, I will introduce our journey towards machines that understand geometry. I will show that by combining our knowledge about the physical world with machine learning, we can achieve much more than a black-box solution. Specifically, I will show how we use non-differentiable components within deep networks and still train as a whole; how we constrain the network to follow physics via deep network architectures and formulations; how we can tailor architectures for solving image correspondence problems; and how we simplify the role of machine learning by turning the problem into hypothesis testing. <br><br><b>Bio:</b> <a target="_blank" href="https://www.cs.ubc.ca/~kmyi/">Kwang Moo Yi</a> is an assistant professor in the Department of Computer Science at the <a target="_blank" href="https://www.cs.ubc.ca/">University of British Columbia (UBC)</a>, and a member of the Computer Vision Lab, CAIDA, and ICICS at UBC. Before, he was at the University of Victoria as an assistant professor, where he is currently an adjunct professor. Prior to being a professor, he worked as a post-doctoral researcher at the Computer Vision Lab in École Polytechnique Fédérale de Lausanne (EPFL, Switzerland), working with Prof. Pascal Fua and Prof. Vincent Lepetit. He received his Ph.D. from Seoul National University under the supervision of Prof. Jin Young Choi. He also received his B.Sc. from the same University. He serves as area chair for top Computer Vision conferences (CVPR, ICCV, and ECCV), as well as AAAI. He is part of the organizing committee for CVPR 2023.
  highlight: 0
  image: Kwang_Moo_Yi.jpeg
  
- date: April 10, 2021
  headline: >-
    Symposium on Geometry Processing (SGP) 2021
  text: >-
    Gruvi is glad to announce that Angel Chang will serve as Conference Chair in the SGP 2021. The Symposium on Geometry Processing (SGP) is the flagship conference in geometry processing. To learn more about the conference please visit <a href="https://sgp2021.github.io/organization">here</a>.
  highlight: 0
  image: angel.png
  
- date: April 2, 2021
  headline: >-
    Talk by Kaichun Mo   
  text: >-
    <b>Talk title:</b> Learning 3D Shape Actionable Information from Simulated Interaction  <br><br><b>Time:</b> April 2, from 3:30 to 4:30PM (PST)  <br><br><b>Abstract:</b> We humans accomplish everyday tasks by interacting with a wide range of 3D objects, with diverse geometry, rich semantics, and complicated structures. One fundamental goal of computational visual perception is to equip intelligent agents with similar capabilities to understand how to meaningfully interact with the 3D environment. While great advances have been achieved in both fields of 3D vision (e.g. object detection, pose estimation, shape reconstruction) and robotic manipulation (e.g. planning, control), we ask the question -- what are good visual representations of 3D shapes for various downstream robotic manipulation tasks? In this talk, I will introduce my recent research taking one step along this direction that learns 3D shape actionable information via large-scale annotation-free learning from simulated interaction. More specifically, I will present two works (i.e. Where2Act, O2O-Afford) that learn 3D shape visual affordance post-conditioned on various primitive manipulation policies, using the large-scale ShapeNet/PartNet dataset and SAPIEN physical simulation environment.<br><br><b>Bio:</b> <a target="_blank" href="https://cs.stanford.edu/~kaichun/">Kaichun Mo</a> is a fifth-year Ph.D. Student in Computer Science at Stanford University, advised by Prof. Leonidas Guibas. Before that, he received his BS.E. degree from the ACM Honored Class at Shanghai Jiao Tong University. His research interests focus on understanding 3D shape structure and semantics for various applications in 3D vision, graphics, and robotic manipulation. He has interned at Adobe Research, Autodesk Research (AI Lab), and Facebook AI Research. He has published papers at CVPR, ECCV, NeurIPS, ICLR, Siggraph Asia, ToG, AAAI.
  highlight: 0
  image: Kaichun_Mo.jpeg
  
- date: March 19, 2021
  headline: >-
    Talk by Animesh Garg   
  text: >-
    <b>Talk title:</b> Building Blocks of Generalizable Autonomy in Robot Manipulation  <br><br><b>Time:</b> March 19, from 3:30 to 4:30PM (PST)  <br><br><b>Abstract:</b> My approach to Generalizable Autonomy posits that interactive learning across families of tasks is essential for discovering efficient representation and inference mechanisms. Arguably, a cognitive concept or a dexterous skill should be reusable across task instances to avoid constant relearning. It is insufficient to learn to “open a door”, and then have to re-learn it for a new door, or even windows & cupboards. Thus, I focus on three key questions-  (1) Representational biases for embodied reasoning, (2) Causal Inference in abstract sequential domains,  and (3) Interactive Policy Learning under uncertainty. In this talk, I will first through example lay bare the need for structured biases in modern RL algorithms in the context of robotics. This will span state, actions, learning mechanisms, and network architectures. Secondly,  we will talk about the discovery of latent causal structure in dynamics for planning. Finally, I will demonstrate how large-scale data generation combined with insights from structure learning can enable sample efficient algorithms for practical systems. In this talk, I will focus mainly on manipulation, but my work has been applied to surgical robotics and legged locomotion as well.<br><br><b>Bio:</b> <a target="_blank" href="https://animesh.garg.tech/">Animesh Garg</a> is a CIFAR Chair Assistant Professor of <a target="_blank" href="https://web.cs.toronto.edu/">Computer Science</a> at the University of Toronto and a Faculty Member at the <a target="_blank" href="https://vectorinstitute.ai/">Vector</a> Institute where he leads the Toronto <a target="_blank" href="http://pair.toronto.edu/">People, AI, and Robotics (PAIR)</a> research group. Animesh is affiliated with Mechanical and Industrial Engineering (courtesy) and <a target="_blank" href="https://robotics.utoronto.ca/">UofT Robotics Institute</a>. Animesh also spends time as a Senior Researcher at <a target="_blank" href="https://www.nvidia.com/en-us/research/">Nvidia Research</a> in ML for Robotics. Prior to this, Animesh earned a Ph.D. from <a target="_blank" href="https://bair.berkeley.edu/">UC Berkeley</a>, and was a postdoc at the <a target="_blank" href="http://ai.stanford.edu/">Stanford AI Lab</a>. His research focuses on machine learning algorithms for perception and control in robotics. His work aims to build Generalizable Autonomy in robotics which involves a confluence of representations and algorithms for reinforcement learning, control, and perception. His work has received multiple Best Paper Awards (ICRA, IROS, Hamlyn Symposium, Neurips Workshop, ICML Workshop) and has been covered in the press (New York Times, Nature, BBC).
  highlight: 0
  image: animesh-garg.jpeg

- date: December 3, 2020
  headline: >-
    Talk by Hadar Averbuch-Elor   
  text: >-
    <b>Talk title:</b> Generation by Decomposition  <br><br><b>Time:</b> December 16, from 1:30 to 2:30PM (PST)  <br><br><b>Abstract:</b> Deep learning has revolutionized our ability to generate novel images and 3D shapes. Neural networks are typically trained to map a high-dimensional latent code to full realistic samples. In this talk, I will present two recent works focusing on generation of handwritten text and 3D shapes. In these works, we take a different approach and generate image and shape samples using a more granular part-based decomposition, demonstrating that the whole is not necessarily “greater than the sum of its parts”. I will also discuss how our generation by decomposition approach allows for a semantic manipulation of 3D shapes and improved handwritten text recognition performance.<br><br><b>Bio:</b> <a target="_blank" href="http://www.cs.cornell.edu/~hadarelor/">Hadar Averbuch-Elor</a> is a postdoctoral researcher at Cornell-Tech working with Prof. Noah Snavely. Her research interests lie in the intersection of computer graphics and computer vision. Currently, her research focuses on understanding and manipulating visual concepts by combining pixels with more structured modalities, including natural language and 3D geometry. She completed her PhD in Electrical Engineering at Tel-Aviv University in Israel where she was advised by Prof. Daniel Cohen-Or. She also held research positions at Facebook and Amazon AI. Hadar has received several awards including the Zuckerman Postdoctoral Scholar Fellowship and the Tel Aviv University President Award for Women.
  highlight: 0
  image: hadar.jpg

- date: December 2, 2020
  headline: >-
    Graphics Interface 2021
  text: >-
    Gruvi is glad to announce that Ali Mahdavi-Amiri and Manolis Savva will serve as general and program co-chair at the Graphics Interface 2021. Graphics Interface is the only conference for computer graphics and human computer interaction. To learn more about the conference please visit <a href="http://graphicsinterface.org/conference/2021/">here</a>.
  highlight: 0
  image: graphics_interface_2021.png

- date: October 10, 2020
  headline: >-
    Keynote and award at ChinaGraph'20
  text: >-
    Richard Zhang will deliver <a href="https://chinagraph2020.xmu.edu.cn/keynotes.html#keynote3" target="_blank">one of the keynote talks</a> (virtually) at ChinaGraph 2020 held in Xiamen, China, on October 23. ChinaGraph is a bi-annual conference on computer graphics in China, the most important gathering of graphics researchers, students, and industries in the country. In another news, &nbsp;<a href="https://pages.tmall.com/wow/cab/tianchi/promotion/alibaba-3d-scene-dataset" target="_blank" >3D-FRONT</a>, a large-scale 3D indoor scene dataset&nbsp;published earlier this year by Richard and colleagues from Alibaba and the Chinese Academy of Sciences, has won the inaugural ChinaGraph Best Dataset Award.
  highlight: 0
  image: chinagraph20.png

- date: September 25, 2020
  headline: >-
    Gruviers Receive Funding from CFI
  text: >-
    Congratulations to Angel Xuan Chang, Yasutaka Furukawa and Manolis Savva for receiving fundings form <b>Canada Foundation for Innovation (CFI)</b>. This funding will allow our researchers to take their transformative discoveries to the next level. More information about the funding and the projects can be found here <a href="http://www.sfu.ca/sfunews/stories/2020/09/17-sfu-research-projects-ready-to-roll-with--2-9m-from-canada-fo.html">here</a>.
  highlight: 0
  image: CFI_funding.png

- date: September 23, 2020
  headline: >-
    Talk by He Wang
  text: >-
    <b>Title:</b> Category-Level Object Perception for Physical Interaction<br><b>Time:</b> 1:30 - 2:30, Wednesday, September 23<br><br><b>Abstract:</b> Deep neural networks have shown great success both in semantic perception tasks, e.g. object recognition and semantic segmentation, and in end-to-end perception for reinforcement learning and robotic tasks. However, it is still unclear how to bridge these two perception paradigms to gain a deep semantic and interaction-driven understanding of physical interaction.<br><br>In this talk, I will focus on how to explore categorical actionable information for the sake of perceiving and understanding physical interactions. First, I will show that learning high-level semantic actionable information, e.g. object state, can help with action planning. Second, I will introduce the problem of estimating category-level 6D pose and 3D size for rigid objects. This category pose can be seen as low-level actionable information and can benefit object manipulation tasks. Lastly, I will present my recent works on curating an articulated object dataset and estimating category-level articulated object pose.<br><br><b>Bio:</b> He Wang is a fifth-year PhD student at Stanford University under the supervision of Prof. Leonidas Guibas. His research interests span across computer vision, geometric computing, and robotics.  In his PhD he contributed to generative modeling of human object interactions, opened up a new direction in estimating category-level pose and size for rigid and articulated objects. He receives Eurographics 2019 best paper honorable mention award and three of his works are accepted as CVPR oral presentations. Prior to his PhD he obtained his bachelor in Microelectronics from Tsinghua University.
  highlight: 0
  image: he_profile.png

- date: September 13, 2020
  headline: >-
    New SFU CS Adjunct Prof
  text: >-
    Kevin (Kai) Xu, a former gruvier from 2008 to 2010, when he worked as a visiting Ph.D. student under the supervision of Richard Zhang, is now resuming his affiliation with GrUVi after being appointed as an Adjunct Professor at SFU CS for a three-year term. Welcome back to GrUVi, Kevin!</p><p style="padding: 0 15px; text-align: justify;">Check <a href="https://kevinkaixu.net/" target="_blank">his website</a> for more information about his recent works in computer graphics and computer vision!
  highlight: 0
  image: kevinxu.jpg

- date: July 8, 2020
  headline: >-
    Gruviers Won the SGP Dataset Award
  text: >-
    Congratulations to Angel Xuan Chang and Manolis Savva, whose work <b>ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes</b> won the 2020 SGP dataset award. ScanNet is an RGB-D video dataset containing 2.5 million views in more than 1500 scans, annotated with 3D camera poses, surface reconstructions, and instance-level semantic segmentations. More information can be found in the paper <a href="http://www.scan-net.org/">here</a>.
  highlight: 0
  image: angel_scannet.png

- date: Jun 23, 2020
  headline: >-
    Gruviers Receive CVPR Awards
  text: >-
    Visual computing researchers from SFU received multiple awards at the annual Conference on Computer Vision and Pattern Recognition (CVPR) this past week. CVPR is the premier conference in computer vision with the highest impact factor among all conferences in computer science and was held virtually for the first time this year from June 14-19. Computing science professor Greg Mori served as one of four program chairs at the conference. <br><br> Zhiqin Chen and Richard Zhang, together with GrUVi alumnus Andrea Tagliasacchi, won the Best Student Paper Award with "BSP-Net: Generating Compact Meshes via Binary Space Partitioning" introduces a deep neural network which applies a classical graphics technique to learn compact shape representations.  <br><br> Yasutaka Furukawa won the PAMI Longuet-Higgins Prize for his CVPR 2007 milestone paper on “multi-view stereo reconstruction”, which has been cited more than 3,000 times! <br><br> Also, Akshay Gadi Patil won the Best Paper Award at the CVPR Workshop on Text and Documents in the Deep Learning Era for his work "READ: Recursive Autoencoders for Document Layout Generation". <br><br> Read more <a href="https://www.sfu.ca/computing/newsandevents/2020/visual-computing-researchers-cvpr.html">here</a>. Well done, gruviers!
  highlight: 0
  image: CVPR_GRUVI.png

- date: Jun 09, 2020
  headline: >-
    GrUVi making waves at CVPR 2020
  text: >-
    <span style="font-weight: 400;">CVPR, the premier conference on computer vision, will be held virtually next week (June 16-20). SFU Computing Science professor Greg Mori is front-n-center as a Program Chair of the major event! GrUVi lab will have an incredible showing at CVPR, with 11 technical papers (5 orals), 3 invited talks, and 4 co-organized workshops!</span></p> <p><br /><br /></p> <p><strong>Workshop co-organization</strong></p> <p>&nbsp;</p> <p align="justify"><span style="font-weight: 400;">GrUViers will co-organize 4 workshops featuring state-of-the-art research:</span></p> <p>&nbsp;</p> <ul align="justify"> <li style="font-weight: 400;"><a href="https://learn3dgen.github.io/"><span style="font-weight: 400;">Learning 3D Generative Models</span></a><span style="font-weight: 400;"></span></li> <li style="font-weight: 400;"><a href="http://www.scan-net.org/cvpr2020workshop/"><span style="font-weight: 400;">ScanNet Indoor Scene Understanding Challenge</span></a><span style="font-weight: 400;"></span></li> <li style="font-weight: 400;"><a href="https://embodied-ai.org/"><span style="font-weight: 400;">Embodied-AI Workshop</span></a><span style="font-weight: 400;"></span></li> <li style="font-weight: 400;"><a href="https://sites.google.com/view/geometry-learning-foundation/"><span style="font-weight: 400;">Deep Learning Foundations of Geometric Shape Modeling and Reconstruction</span></a><span style="font-weight: 400;"> </span></li> </ul> <p><br /><br /></p> <p><strong>Invited workshop talks</strong></p> <p>&nbsp;</p> <p align="justify"><span style="font-weight: 400;">Yasutaka Furukawa will give a talk at the aforementioned &ldquo;ScanNet Indoor Scene Understanding Challenge&rdquo; as well as the &ldquo;</span><a href="https://scene-understanding.com/"><span style="font-weight: 400;">3D Scene Understanding for Vision, Graphics, and Robotics</span></a><span style="font-weight: 400;">&rdquo; workshop </span><span style="font-weight: 400;">, while </span><span style="font-weight: 400;">Manolis Savva will participate as an invited speaker at the &ldquo;</span><a href="https://fadetrcv.github.io/"><span style="font-weight: 400;">Fair, Data, Efficient and Trusted Computer Vision</span></a><span style="font-weight: 400;">&rdquo; workshop.</span></p> <p><br /><br /></p> <p><strong>Technical Papers and GrUVi authors</strong></p> <p>&nbsp;</p> <p align="justify"><span style="font-weight: 400;">Congratulations to all authors, especially to Dr. Ping Tan, who got five accepted papers! The full list of papers featured on CVPR 2020 can be accessed </span><a href="http://cvpr2020.thecvf.com/program/main-conference"><span style="font-weight: 400;">here</span></a><span style="font-weight: 400;">. In particular, GrUVi papers covered different topics:</span></p> <p>&nbsp;</p> <ul align="justify"> <li style="font-weight: 400;"><span style="font-weight: 400;">3D From a Single Image and Shape-From-X</span></li> <ul> <li style="font-weight: 400;"><span style="font-weight: 400;">BSP-Net: Generating Compact Meshes via Binary Space Partitioning (<strong>Zhiqin Chen</strong>, Andrea Tagliasacchi, <strong>Hao Zhang</strong> - </span><strong>oral</strong><span style="font-weight: 400;">)</span></li> <li style="font-weight: 400;"><span style="font-weight: 400;">Bundle Pooling for Polygonal Architecture Segmentation Problem (Huayi Zeng, <strong>Kevin Joseph</strong>, Adam Vest, <strong>Yasutaka Furukawa</strong>)</span></li> <li style="font-weight: 400;"><span style="font-weight: 400;">Cascade Cost Volume for High-Resolution Multi-View Stereo and Stereo Matching (Xiaodong Gu, Zhiwen Fan, Siyu Zhu, Zuozhuo Dai, <strong>Feitong Tan</strong>, <strong>Ping Tan</strong> - </span><strong>oral</strong><span style="font-weight: 400;">)</span></li> <li style="font-weight: 400;"><span style="font-weight: 400;">Conv-MPN: Convolutional Message Passing Neural Network for Structured Outdoor Architecture Reconstruction (<strong>Nelson Nauata</strong>, <strong>Fuyang Zhang</strong>, <strong>Yasutaka Furukawa</strong>)</span></li> <li style="font-weight: 400;"><span style="font-weight: 400;">PQ-NET: A Generative Part Seq2Seq Network for 3D Shapes (Rundi Wu, Yixin Zhuang, Kai Xu, <strong>Hao Zhang</strong>, Baoquan Chen)</span></li> <li style="font-weight: 400;"><span style="font-weight: 400;">Self-Supervised Human Depth Estimation From Monocular Videos (<strong>Feitong Tan</strong>, Hao Zhu, Zhaopeng Cui, Siyu Zhu, Marc Pollefeys, <strong>Ping Tan</strong>)</span></li> </ul> <li style="font-weight: 400;"><span style="font-weight: 400;">3D From Multiview and Sensors; Computational Photography; Efficient Training and Inference Methods for Networks</span></li> <ul> <li style="font-weight: 400;"><span style="font-weight: 400;">End-to-End Learning Local Multi-View Descriptors for 3D Point Clouds (Lei Li, Siyu Zhu, Hongbo Fu, <strong>Ping Tan</strong>, Chiew-Lan Tai)</span></li> </ul> <li style="font-weight: 400;"><span style="font-weight: 400;">3D From Multiview and Sensors; Face, Gesture, and Body Pose; Image and Video Synthesis</span></li> <ul> <li style="font-weight: 400;"><span style="font-weight: 400;">Deep Facial Non-Rigid Multi-View Stereo (<strong>Ziqian Bai</strong>, Zhaopeng Cui, <strong>Jamal Ahmed Rahim</strong>, Xiaoming Liu, <strong>Ping Tan</strong>)</span></li> </ul> <li style="font-weight: 400;"><span style="font-weight: 400;">Motion and Tracking</span></li> <ul> <li style="font-weight: 400;"><span style="font-weight: 400;">LSM: Learning Subspace Minimization for Low-Level Vision (<strong>Chengzhou Tang</strong>, Lu Yuan, <strong>Ping Tan</strong> - </span><strong>oral</strong><span style="font-weight: 400;">)</span></li> </ul> <li style="font-weight: 400;"><span style="font-weight: 400;">Segmentation, Grouping, and Shape</span></li> <ul> <li style="font-weight: 400;"><span style="font-weight: 400;">AdaCoSeg: Adaptive Shape Co-Segmentation With Group Consistency Loss (<strong>Chenyang Zhu</strong>, Kai Xu, Siddhartha Chaudhuri, Li Yi, Leonidas J. Guibas, <strong>Hao Zhang</strong> - </span><strong>oral</strong><span style="font-weight: 400;">)</span></li> </ul> <li style="font-weight: 400;"><span style="font-weight: 400;">Vision for Robotics and Autonomous Vehicles</span></li> <ul> <li style="font-weight: 400;"><span style="font-weight: 400;">SAPIEN: A SimulAted Part-Based Interactive ENvironment (Fanbo Xiang, Yuzhe Qin, Kaichun Mo, Yikuan Xia, Hao Zhu, Fangchen Liu, Minghua Liu, <strong>Hanxiao Jiang</strong>, Yifu Yuan, He Wang, Li Yi, <strong>Angel X. Chang</strong>, Leonidas J. Guibas, Hao Su - </span><strong>oral</strong><span style="font-weight: 400;">)</span></li> </ul> </ul> <p>
  highlight: 0
  image: CVPR_GRUVI.png
  
- date: Jun 07, 2020
  headline: >-
    GrUVi tackles COVID-19 using AI
  text: >-
    SFU researchers helped to develop an AI system capable of assisting resident and less experienced doctors look over a data set and make a quick diagnosis before a senior doctor can step in. This is accoding to Yağız Aksoy, a gruvier and also a member of the team that proposed the diagnosis tool, which is currently in the validation phase at St. Paul’s Hospital in Vancouver, Canada. Read more about it <a href="http://www.sfu.ca/sfunews/stories/2020/06/sfu-researchers-help-develop-ai-tool-for-speedy-covid-19-diagnos.html">here</a>. Thank you for your hard work, Dr. Aksoy!
  highlight: 0
  image: covid.jpg

- date: Oct 24, 2019
  headline: >-
    LOGAN - SIG Asia Press Release
  text: >-
    Congratulations to Kangxue, whose work <b>LOGAN: Unpaired Shape Transform in Latent Overcomplete Space</b> will be featured for press release at SIGGRAPH Asia 2019!<br><br>LOGAN is able to learn what shape features to preserve during shape translation, either local or non-local, whether content or style, depending solely on the input domains for training, which was an improvement over the state of the art.<br><br>LOGAN is an abbreviation for Latent Overcomplete GAN. Richard Zhang, who is also the last author, created the fun acronym.<br><br>
  highlight: 0
  image: logan.jpg

- date: Jul 23, 2019
  headline: >-
    IGS'19 Organized by GrUVi
  text: >-
    The International Geometry Summit (IGS) 2019, organized by  Richard Zhang and Ali Mahdavi-Amiri, took place from 17th June to the 21th June 2019 at SFU Harbour Center in Vancouver, Canada. IGS 2019 included four conferences: the Symposium on Solid and Physical Modelling, Shape Modeling International, SIAM Conference on Computational Geometric Design, and International Conference on Geometric Modelling and Processing. IGS 2019 featured state of the art researches in its technical paper sessions along with 12 keynote speeches from prominent researchers in the area of geometry.</p><p style="text-align: justify;">Congratulations to Richard Zhang and Ali Mahdavi-Amiri for the successful organization and thanks to all GrUVi students that volunteered to make IGS'19 a success!
  highlight: 0
  image: igs19.png

- date: Jul 22, 2019
  headline: >-
    Richard's SGP Keynote Speech
  text: >-
    Richard Zhang was featured in the Eurographics Symposium on Geometry Processing (SGP) as a keynote speaker! His speech was titled “Can Machines Learn to Generate 3D Shapes?”.</p><p style="text-align: justify;">In his talk, Richard highlighted the representation, data, and output challenges that researchers must tackle and how his research has shaped itself to address these challenges.</p><p style="text-align: justify;">One of the key issues in this domain is not generate shapes that look right; instead, they need to serve their intended function while displaying the right part connections, arrangements, and geometry.
  highlight: 0
  image: Richard_SGP.jpeg

- date: Jul 9, 2019
  headline: >-
    Xiaoming Liu Visits SFU
  text: >-
    <a href"http://www.cse.msu.edu/~liuxm" target="_blank">Dr. Xiaoming Liu</a> visited SFU today following an invitation from Dr. Yasutaka Furukawa! His talk titled "Inverse Graphics for 3D Modeling and Reconstruction: from Face to Generic Objects" has the following abstract: <br><br>"Reconstructing the detailed and complete 3D surface of an object from a single 2D image is a long standing computer vision problem. In this talk, we present an inverse graphics-based framework to learn a 3D face model from a large set of in-the-wild 2D face images, without the need of capturing 3D scans. We also extend this framework to high-fidelity face modeling, as well as generic object modeling and 3D reconstruction. In the end, we will briefly overview other research efforts in the Computer Vision Lab at Michigan State University, including face anti-spoofing, explainable recognition, early sensor fusion of LiDAR and RGB, 2D/3D object detection from urban driving videos, etc."
  highlight: 0
  image: xiaoming.jpg

- date: Jul 3, 2019
  headline: >-
    Yağız Aksoy Joins GrUVi
  text: >-
    GrUVi is glad to announce that Yagiz Aksoy will join our team this August. He is a PhD student of Marc Pollefeys at ETH Zurich. During his PhD, he spent a year at MIT CSAIL working with Wojciech Matusik and three years at Disney Research Zurich.<br>His research is at the intersection of computer vision and computer graphics, focusing on analyzing images to allow for realistic manipulation of photographs. His research has resulted in publications at venues such as SIGGRAPH, CVPR, and ACM Transactions on Graphics.<br>Welcome to the GrUVi team, Yagiz!
  highlight: 0
  image: yagiz.jpg

- date: Jun 3, 2019
  headline: >-
    Zhiqin's and Jon's Thesis Defense
  text: >-
    The GrUVi team congratulates both Zhiqin and Jon for their sucessful MSc theses defense!<br>Jon's thesis is on A Qualitative and Localized Evaluation for 3D Indoor Scene Synthesis<br>Zhiqin's thesis is on IM-NET: Learning Implicit Fields for Generative Shape Modeling<br>Zhiqin's thesis defence also received the honor of "pass as is" today. Both of them will start as PhDs at GrUVi this September. 
  highlight: 0
  image: zhiqin_jon.jpg

- date: May 23, 2019
  headline: >-
    Kangxue Yin wins an Award!
  text: >-
    The GrUVi team congratulates Kangxue Yin, whom received the prestigious Chinese Government Award for Outstanding Self-financed Students Abroad!</p><p style="text-align: justify;">This award was established in 2003 by the&nbsp;<a title="China Scholarship Council" href="https://en.wikipedia.org/wiki/China_Scholarship_Council">China Scholarship Council</a>. The worldwide recipients are chosen annually based on a record of outstanding accomplishments in any discipline.</p><p style="text-align: justify;">This award is considered the highest award given by Chinese government for Chinese graduate students studying abroad who do not receive regular financial support from Chinese government.</p><p style="text-align: justify;">Currently, this award is granted to only 500 students every year. Since there are around half a million Chinese students to study abroad per year, this a highly competitive award. For the academic year 2018, only 6 awardees were based in British Columbia, Canada. Among them, Kangxue was the only student majoring in Computer Science.
  highlight: 0
  image: kangxue_award.jpg

- date: May 1, 2019
  headline: >-
    Accepted Paper on CVPR
  text: >-
    A paper by Zhiqin Chen and Hao Zhang on learning implicit fields for generative modeling of 3D shapes will be presented at CVPR 2019!<br>It has also been invited to be presented at the <a href="https://3dscenegen.github.io/">Workshop on 3D Scene Generation</a> at CVPR; see <a href="https://arxiv.org/abs/1812.02822">paper on arXiv</a>.<br>Congratulations to both Zhiqin and Richard!
  highlight: 0
  image: zhiqin_cvpr.png

- date: April 14, 2019
  headline: >-
    New and Returning GRuVIers!
  text: >-
    The GrUVi team would like to welcome three SFU undergrad students who are joining the lab for summer/visiting research:</p> <ul> <li style="line-height: 100%; text-align: justify;">Leo Li - to start in the summer as a VPA USRA working on representation learning;</li> <li style="line-height: 100%; text-align: justify;">Atticus Shi - who is working on a geometric optimization problem related to fixture design for CNC machining;</li> <li style="line-height: 100%; text-align: justify;">Azmarie Wang - to start in the summer as a special project student working on creative design problems.</li> </ul> <p align="justify">In addition, Xiaogang Wang is joining us as a visiting PhD from Beihang University, the same university as Jiongchao. He comes with an already impressive research record (one SIG Asia and one CVPR), working with Kevin, a GrUVi alumni himself.</p> <p align="justify">Fenggen (Fogg) Yu, will be a new PhD starting this fall. Fenggen is from Nanjing University and he had already collaborated with GrUVi members on a ACM TOG paper. He also has a CVPR paper this year.</p> <p align="justify">We are also pleased to announce that two current members of the lab, Zhiqin and Jon, will continue as PhD students this fall.</p> <p align="justify">Finally, Akshay is returning from his internship at Amazon (Israel) and Manyi, as a newly minted PhD, will be back as a postdoc this Summer.
  highlight: 0
  image: gruvi_logo.png

- date: October 2, 2018
  headline: >-
    5 SIG Asia 2018 papers
  text: >-
    GrUVi members co-author five technical papers at SIGGRAPH Asia 2018, which will be held at Tokyo in December 4-7. In particular, Wallace, Shuhua, Akshay, Manyi, Ali, and Han all got their very first SIG papers! The papers cover topics in fabrication, machine learning, shape and scene modeling, NLP, and even a fun (fabricable) puzzle! The papers are: <a target="_blank" rel="noopener noreferrer" href="http://www.sfu.ca/~agadipat/publications/2018/T2S/project_page.html">"Language-Driven Synthesis of 3D Scenes Using Scene Databases"</a>, <a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/site/alimahdaviamiri/projects/reversible-shapes">"Construction and Fabrication of Reversible Shape Transforms"</a>, <a target="_blank" rel="noopener noreferrer" href="http://gruvi.cs.sfu.ca/project/eulerianwires/">"Fabricable Eulerian Wires for 3D Shape Abstraction"</a>, <a target="_blank" rel="noopener noreferrer" href="https://kevinkaixu.net/projects/scores.html">"SCORES: Shape Composition with Recursive Substructure Priors"</a>, and <a target="_blank" rel="noopener noreferrer" href="http://irc.cs.sdu.edu.cn/~xuelin/prefab/index.html">"3D Fabrication with Universal Building Blocks and Pyramidal Shells"</a>. Congratulations to all authors!
  highlight: 0
  image: ma_siga18_t2s.png

- date: August 23, 2018
  headline: >-
    Gruviers Volunteered for SIG'2018
  text: >-
    Two gruviers were student volunteers (SV) at the SIGGRAPH 2018 conference. While the attendees were certainly thankful for all the work that all the volunteers put in the event, our gruvi volunteers described how valuable the experience was for them! Zhiqin got the chance to use the hardware available at the exhibition hall to print the awesome gruvi logo on the hat shown in the picture. He described the great impact that experiencing the latest developments on VR technology had on him:<br /><br /> "I'm honored to be a student volunteer of such a great conference. VR was definitely a highlight of SIGGRAPH 2018. There were many showcases of applying haptic technology to VR and utilizing VR for designing and creating content. The immersive pavilion was awesome and provided me all kinds of VR experiences. I am looking forward to next SIGGRAPH!"<br /><br />Akshay, on the other hand, emphasized the connections he was able to forge during his time as a volunteer:<br /><br />"This was my first SIGGRAPH and my first time as a SIG-SV. The kind of atmosphere, the exuberance of energy and experience that I felt was surreal and I was left wanting for more when it ended. Memories of a lifetime with awesome fellow SV's, coordinating various programs and above all, the latest technology!! Definitely want to relive this again at SIG'19."
  highlight: 0
  image: gruvi_hat.jpg


- date: August 21, 2018
  headline: >-
    GrUVi presentations @ SIG'2018
  text: >-
    SIGGRAPH 2018 was held in Vancouver from August 12 to 16, at the Vancouver Convention Centre. The majority of GrUVi members attended the conference, some as paper presenters and some as student volunteers. This year, the lab contributed four papers that were presented in the Technical Papers program. Ali presented his paper on semi-supervised analysis of 3D shape styles and Kangxue presented his paper on P2P-NET, both on Thursday, in the paper session on Shape Analysis. Also notably, long-term collaborator with GrUVi and adjunct professor with the SFU School of Computing Science, Prof. Daniel Cohen-Or, is featured as the annual SIGGRAPH Achievement Award winner. Danny has been collaborating with Richard Zhang and students in the lab since 2008!
  highlight: 0
  image: Kangxue_Ali.PNG

- date: August 21, 2018
  headline: >-
    Eugene's 60th Aniversary Celebrated
  text: >-
    A special event honouring Professor Eugene Fiume, on the occasion of his 60-th birthday, was held at the SFU Harbour Center on August 17, right after SIGGRAPH 2018. Many of Eugene's first-generation PhDs from the University of Toronto attended the celebratory workshop and gave their account of fun and inspiring stories about what it was like to be his graduate students. Eugene's computer graphics instructor during his undergraduate years at the University of Waterloo provided hint of how Eugene was already "ahead of the class" then. The event featured Prof. Pat Hanrahan from Stanford University, as the keynote speaker. Pat spoke of "theory vs. practice" to highlight how over the years, Eugene has been among the rare group of people in computer graphics, who have emphasized the importance of theory in the field.
  highlight: 0
  image: eugene_event1.jpg

- date: July 22, 2018
  headline: >-
    12 papers from SFU at ECCV 18
  text: >-
    Congratulations to all SFU researchers that were able to have an impressive count of 12 papers accepted at the European Conference on Computer Vision 2018 (ECCV 2018)! ECCV is considered, together with ICCV and CVPR, one of the top level conferences in computer vision. Here is the full list of accepted papers with SFU co-authors:  <br /><br />&#9679;"Hierarchical Relational Networks for Group Activity Recognition and Retrieval" by  Mostafa Ibrahim*, Simon Fraser University; Greg Mori, Simon Fraser University;<br />&#9679;"Neural Procedural Reconstruction for Residential Buildings" by  Huayi Zeng*, Washington University in St.Louis; Jiaye Wu, Washington University in St.Louis; Yasutaka Furukawa, Simon Fraser University;<br />&#9679;"IM2Hand3D: Leveraging Multi-task Network for 3D Hand Pose Estimation from a Color Image" by  Xiaoming Deng*, Chinese Academy of Sciences; Wenyong Zheng, Chinese Academy of Sciences ; Yinda Zhang, Princeton University; Jian Shi, Chinese Academy of Sciences ; Ping Tan, Simon Fraser University; Liang Chang, Beijing Normal University; Yuying Zhu, Chinese Academy of Sciences;<br />&#9679;"FloorNet: A Unified Framework for Floorplan Reconstruction from 3D Scans" by  Chen Liu*, Washington University in St. Louis; Jiaye Wu, Washington University in St.Louis; Yasutaka Furukawa, Simon Fraser University;<br />&#9679;"Probabilistic Video Generation using Holistic Attribute Control" by  Jiawei He*, Simon Fraser University; Andreas Lehrmann, Facebook; Joe Marino, California Institute of Technology; Greg Mori, Simon Fraser University; Leonid Sigal, University of British Columbia;<br />&#9679;"Constraints Matter in Deep Neural Network Compression" by  Changan Chen, Simon Fraser University; Fred Tung*, Simon Fraser University; Naveen Vedula, Simon Fraser University; Greg Mori, Simon Fraser University;<br />&#9679;"Characterize Adversarial Examples Based on Spatial Consistency Information for Semantic Segmentation" by  CHAOWEI XIAO, University of Michigan, Ann Arbor; Ruizhi Deng, Simon Fraser University; Bo Li*, University of Illinois at Urbana Champaign; Fisher Yu, UC Berkeley; mingyan liu, university of Michigan, Ann Arbor; Dawn Song, UC Berkeley;<br />&#9679;"Faces as Lighting Probes via Unsupervised Deep Highlight Extraction" by  Renjiao Yi*, Simon Fraser University; Chenyang Zhu, Simon Fraser University; Ping Tan, Simon Fraser University; Stephen Lin, Microsoft Research;<br />&#9679;"Sparsely Aggregated Convolutional Networks" by  Ligeng Zhu*, Simon Fraser University; Ruizhi Deng, Simon Fraser University; Michael Maire, Toyota Technological Institute at Chicago; Zhiwei Deng, Simon Fraser University; Greg Mori, Simon Fraser University; Ping Tan, Simon Fraser University;<br />&#9679;"RIDI: Robust IMU Double Integration" by  Hang Yan*, Washington University in St. Louis; Qi Shan, Zillow Group; Yasutaka Furukawa, Simon Fraser University;<br />&#9679;"Object Level Visual Reasoning in Videos" by  Fabien Baradel, LIRIS; Natalia Neverova*, Facebook AI Research; Christian Wolf, INSA Lyon, France; Julien Mille, INSA Centre Val de Loire; Greg Mori, Simon Fraser University.<br />&#9679;"SketchyScene: Richly-Annotated Scene Sketches" by  Changqing Zou*, University of Maryland (UMD); Qian Yu, Queen Mary University of London; Ruofei Du, UMD; Haoran Mo, sun yat sen university; Yi-Zhe Song, Queen Mary University of London; Tao Xiang, Queen Mary, University of London, UK; Chengying Gao, sun yat sen university; Baoquan Chen, Shandong University; Hao Zhang, SFU.
  highlight: 0
  image: eccv18.png

- date: May 18, 2018
  headline: >-
    Three new visiting Gruviers!
  text: >-
    GrUVi welcomes three new visiting students this summer: <a href="https://www.cse.iitb.ac.in/~manas/">Manas Bhargave</a>, IIT Bombay undergrad and visiting under MITACS-IIT; Ruiqi Ni, an undergrad student from University of Science and Technology (USTC) China and Chen Song, SFU-ZJU DDP student under USRA. <br /><br /> Welcome to GrUVi!
  highlight: 0
  image: threenew.png

- date: May 17, 2018
  headline: >-
    GrUVi co-authors three SIG'18 papers
  text: >-
    Three papers co-authored by GrUVi members have been accepted at SIGGRAPH 2018: P2P-NET: Bidirectional Point Displacement Net for Shape Transform, Predictive and Generative Neural Networks for Object Functionality, and DSCarver: Decompose-and-Spiral-Carve for Subtractive Manufacturing. P2P-NET was first-authored by GrUVi's PhD student Kangxue Yin. For more details, please visit the <a href="http://gruvi.cs.sfu.ca/publications/">publications page</a>.
  highlight: 0
  image: P2P-NET.PNG

- date: May 16, 2018
  headline: >-
    Two talks at SFU-ZJU Symposium
  text: >-
    Richard and Ping give talks at &nbsp;<a href="http://www.cad.zju.edu.cn/home/dengcai/Symposium2018/">"Third SFU-ZJU Joint Symposium on Big Data and Visual Computing"</a>. The Third Joint Symposium on Big Data and Visual Computing Research is a forum where researchers and students from the two universities will meet, exchange ideas, and explore opportunities.
  highlight: 0
  image: richard_ping.png

- date: April 12, 2018
  headline: >-
    Kangkang's NSERC DAS Award
  text: >-
    Congrats to Kangkang who has received a NSERC Discovery Accelerator Supplement (DAS) for 2018. Each year 125 applicants to NSERC Discovery grants receive this award, which comes with $40K per year for three years on top of a Discovery Grant award! <br /><br /> The DAS Program provides substantial and timely resources to researchers who have a superior research program that is highly rated in terms of originality and innovation, and who show strong potential to become international leaders within their field. Furthermore, the Discovery Grants Program prioritizes research with long-term goals and recognizes the creativity and innovation that are at the heart of all research advances. <br /><br />Well done Kangkang!
  highlight: 0
  image: KKYIN.jpg

- date: April 10, 2018
  headline: >-
    Yasu's CS-Can/Info-Can Award
  text: >-
    Congrats to Yasu who has received an Outstanding Young CS Researcher Award for 2017.  <br /><br />These prizes recognize excellence in research, and are made to top young faculty members in Canadian Computer Science Departments/Schools/Faculties who are within the first 10 years of their career beyond the completion of their PhD.<br /><br />Well done Yasu!
  highlight: 0
  image: furukawa4.png

- date: April 8, 2018
  headline: >-
    GI'18 to feature two GrUVi alumni
  text: >-
    Graphics Interface 2018 (GI'18) will be held in York University, May 8-11. Two of our GrUVi alumni, Oliver van Kaick and Andrea Tagliasacchi, are invited speakers on the program!  <br /><br />Graphics Interface is an annual international conference devoted to computer graphics and human-computer interaction (HCI). GI is the longest running conference in the field (the first conference was held in 1969), consistently attracting high-quality submissions from graphics, HCI, as well as visualization.
  highlight: 0
  image: oliver_andrea.jpg

- date: February 23, 2018
  headline: >-
    Yasu's 2018 Google Research Award
  text: >-
    GrUVi congratulates Yasu Furukawa, who received a Google Research Award in the current cycle! Yasu's project is titled "Automatic Floorplan Generation from Tango", and is valued at $43,000 (USD).  The works funded through Google Research Awards tend to have a high impact, since research results are often published at top conferences and in top publications in Computer Science.  <br /><br />Well done Yasu!
  highlight: 0
  image: news_3.PNG


- date: October 13, 2017
  headline: >-
    SIG Asia and ICCV 2017 papers
  text: >-
    GrUVi members co-author two technical papers:&nbsp;<a href="http://www.cs.sfu.ca/~haoz/pubs/hu_siga17_icon3.pdf">"Learning to Predict Part Mobility from a Single Static Snapshot"</a> and <a href="http://www.cs.sfu.ca/~haoz/pubs/zou_siga17_group.pdf">"Learning to Group Discrete Graphical Patterns"</a>; and <a href="https://3dworldsblog.wordpress.com/">one course at SIGGRAPH Asia 2017</a>, to be held in Bangkok, Thailand, November 27-30. At ICCV 2017, three papers co-authored by GrUVi members have been presented.
  highlight: 0
  image: news_1.PNG

- date: October 13, 2017
  headline: >-
    Gruvi welcomes Jon Liu!
  text: >-
    Jon Liu as Gruvi's new MSc student. Jon obtained his Master's degree from National Tsinghua University in computer graphics and since then, he has worked in the industry for many years. He recently immigrated to Canada and started his grad studies at SFU in the summer this year. Jon is interested in robotic 3D vision problems. Welcome Jon!
  highlight: 0
  image: jonliu.jpg

- date: October 1, 2017
  headline: Conference co-chairs
  text: GrUVi faculty Yasu Furukawa will be a program co-chair for 3DV 2017, which will be held in Qingdao, China between October 10 and 12. Richard Zhang will also be a program co-chair for Computer Graphics International (CGI) 2018, which will be hosted at Bintan Island, Indonesia, June 11-14, 2018.
  highlight: 0
  image: news_3.PNG


- date: September 19, 2017
  headline: Rui Ma's thesis "pass as is"
  text: Rui has successfully defended his PhD thesis on "Sub-Scene Level Analysis and Synthesis of 3D Indoor Scenes". The thesis and defence has been designated with a "pass as is" distinction by the defence committee members Oliver Deussen (external examiner), Yasu (internal examiner), Ze-Nian (thesis committee members), and Kangkang (chair). Rui Ma also landed a position at Research Scientist at Altumview Systems Inc. Congratulations Rui!
  highlight: 0
  image: ruima.png

- date: August 27, 2017
  headline: Warunika wins best paper award
  text: The paper "An Exquisite Corpse Tool for Collaborative 3D Shape Design", co-authored by Warunika, Parmit Chilana, Daniel Cohen-Or, and Richard Zhang won a best paper award at the recent CAD/Graphics conference. This work was part of Warunika's MSc thesis; she graduated in Dec 2016 and is now at IBM.
  highlight: 0
  image: news_2.PNG

- date: August 26, 2017
  headline: GRASS featured at SIG'17
  text: The paper "Generative Recursive Autoencoder for Shape Structures (GRASS)" co-authored by Prof. Richard Zhang and former GrUVi member Kai Xu, was selected as one of the six technical papers from SIGGRAPH 2017 for press release. See the press release article <a href="https://www.eurekalert.org/pub_releases/2017-07/afcm-md3071817.php">here</a> and an <a href="https://www.sfu.ca/fas/news-and-outreach/years/2017/grass-a-new-algorithm-for-3d-content-creation-to-be-featured-at-siggraph.html">invited article</a> by Richard Zhang on SFU's official website.
  highlight: 0
  image: news_4.PNG

- date: August 25, 2017
  headline: Richard keynote talk at CAD/Graphics
  text: Richard Zhang gave a keynote talk on "Can Machines Learn to Generate 3D Shapes" at the Biannual International Conference on Computer Aided Design and Graphics (CAD/Graphics) in Zhangjiajie, China.
  highlight: 0
  image: Richard.jpeg

- date: August 10, 2017
  headline: GrUVi co-authors three SIG'17 papers
  text: Three papers co-authored by GrUVi members have been accepted to SIGGRAPH 2017&#58; <a href="http://kevinkaixu.net/projects/grass.html">GRASS:Generative Recursive Autoencoders for Shape Structures</a>, <a href="http://gruvi.cs.sfu.ca/project/timeslice/">Time Slice Video Synthesis by Robust Video Alignment</a>, and <a href="http://www.cs.sfu.ca/~haoz/pubs/zhu_sig17_scsr.pdf">Deformation-Driven Shape Correspondence via Shape Recognition</a>.<br /><br />Two of these papers are first-authored by PhD students from GrUVi <a href="http://www.zhpcui.org/"> Zhaopeng Cui</a> and <a href="http://www.sfu.ca/~cza68/">Chenyang Zhu</a>. In addition, one paper accepted to ACM Transaction on Graphics, <a href="http://www.cs.sfu.ca/~haoz/pubs/hu_tog17_style.pdf">Co-Locating Style-Defining Elements on 3D Shapes</a>, will also be presented at SIGGRAPH 2017 in Los Angeles. Collaborators on these papers include researchers from Adobe Research, Tel Aviv University, Stanford University, National University of Defense Technology, Carleton University, IIT Bombay, Shenzhen University, and University of Cyprus.
  highlight: 0
  image: SIG17.png

- date: July 29, 2017
  headline: Zhaopeng goes to ETH
  text: Zhaopeng, who successfully defended his PhD thesis earlier this month, will start his postdoc position at ETH. His thesis also received the rare distinction of "pass as is". Previous gruviers who received such a distinction include Ibraheem Alhashim (2015), Andrea Tagliasacchi (2013), and Oliver van Kaick (2011). Congratulations Zhaopeng!
  highlight: 0
  image: zhaopeng.png

- date: July 25, 2017
  headline: Zhiqhin and Manyi are new Gruviers!
  text: Gruvi welcomes two new members, Zhiqin Chen and Manyi Li, who will join our group during Fall 2017. Zhiqin is a new master student who obtained his bachelor's degree from Shanghai Jiaotong University, while Manyi is a visiting Ph.D. from Shandong University, China. Welcome!
  highlight: 0

- date: July 22, 2017
  headline: Changqing Zou goes to UMIACS
  text: Postdoc Changqing Zou will take up an Assistant Research Scientist position at the University of Maryland Institute for Advanced Computer Studies (UMIACS). Congratulations Changqing!
  highlight: 0

- date: May 9, 2017
  headline: Ibraheem speaks at KAUST
  text: GrUVi alumni Ibraheem Alhashim, who was a PhD student supervised by Richard Zhang between 2011 and 2015, was recently invited to speak at the <a href="https://vcc.kaust.edu.sa/Conference-2017/Pages/default.aspx">KAUST Visual Computing (KAUST RC-VC) “ Modeling and Reconstruction conference</a>. <a href="https://vcc.kaust.edu.sa/Conference-2017/Pages/Speakers.aspx">Speakers at the conference</a> include many of the top experts in the fields of computer graphics and visual computing. Please follow <a href="https://www.kaust.edu.sa/en/news/visualizing-the-future-of-computing?utm_content=buffer0c13e&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">this link</a> for news coverage on Ibraheem's talk and other presentations at the conference.
  highlight: 0
  image: ibrahimKAUST.jpg

- date: May 1, 2017
  headline: New GrUVi faculty Kangkang Yin
  text: It is official! <a href="http://www.cs.sfu.ca/~kkyin/">Prof. Kangkang Yin</a> will be joining SFU CS as an Associate Professor starting July 2017. As one of the leading experts in computer animation and simulation, she will be a fantastic addition to the GrUVi lab. Most recently, KangKang Yin was an Associate Professor in the Department of Computer Science at the National University of Singapore. She worked as an Associate Researcher at Microsoft Research Asia from 2008 to 2010, after she obtained her PhD degree from the University of British Columbia in 2007.
  highlight: 0
  image: KKYIN.jpg

- date: December 23, 2016
  headline: Jaime's Sucessful Msc Thesis Defense
  text: Congrats to Jaime for successfully defending his MSC thesis on "Towards Learning of a Joint Geometry-Structure Manifold for Shape Exploration".<br /><br /> Here is the abstract of his thesis.<br /><br /> We present a first attempt at producing a continuous generative model of 3D objects from a joint representation that incorporates the discrete structural variability as well as the continuous geometric variability that are often present in collections of man-made shapes. Starting from a set of compatibly segmented shapes, our main contribution consists in demonstrating the construction of the joint representation. Then, by using Gaussian Process learning to produce a predictive manifold from the joint representation, we investigate its capabilities and limitations for reproducing and synthesizing new shapes.
  highlight: 0
  image: Jaime.png

- date: December 9, 2016
  headline: Warunika's Successful Msc Thesis Defense
  text: Congrats to Warunika for successfully defending her MSc thesis on "ExquiMo&#58; An Exquisite Corpse Tool for Co-Creative 3D Shape Modeling". The researchers&nbsp;would like to assure you that no person, dog, or any other animals were killed as the result of conducting this thesis research.<br /><br /> Here is the abstract of her work:<br /><br /> We introduce a shape modeling tool, ExquiMo, which is guided by the idea of improving the creativity of 3D shape designs through collaboration. Inspired by the game of Exquisite Corpse, our tool allocates distinct parts of a shape to multiple players who model the assigned parts in a sequence. Our approach is motivated by the understanding that effective surprise leads to creative outcomes. Hence, to maintain the surprise factor of the output, we conceal the previously modeled parts from the most recent player. Part designs from individual players are fused together to produce an often unexpected, hence creative, end result. We demonstrate the effectiveness of collaborative modeling for both man-made and natural shapes. Our results show that, when compared to models designed by individual users, multi-user collaborative modeling via ExquiMo tends to lead to more creative designs in terms of the most common criteria used to identify creative artifacts.
  highlight: 0
  image: Warunika.jpg

- date: September 7, 2016
  headline: "New students joining GrUVi"
  text: Nine new members are joining the&nbsp;GrUVi&nbsp;lab in the fall semester of 2016.&nbsp;We welcome:<br /><br /> Ali&nbsp;Mahdavi-Amiri, a new postdoc&nbsp;to start in January 2017, who obtained his&nbsp;PhD from&nbsp;University of Calgary, Calgary, Canada,&nbsp;his&nbsp;MSc from&nbsp;Sharif University of Technology,&nbsp;Tehran, Iran, and his BSc from&nbsp;Ferdowsi&nbsp;University of&nbsp;Mashhad,&nbsp;Mashhad, Iran.<br /><br /> Han Liu, a new postdoc&nbsp;starting in June 2016, who obtained her PhD&nbsp;from&nbsp;King Abdullah University of Science and Technology, Saudi Arabia, her MSc from&nbsp;Xiamen&nbsp;University, China, and her BSc from&nbsp;Huangshang&nbsp;University, China.<br /><br /> Kiana Mostaghasi, a new MSc student starting in September 2016, who obtained her BSc from&nbsp;Amirkabir University of Technology, Iran.<br /><br /> Nelson Nuata, a new MSc student starting in September 2016, who obtained B.Eng. from&nbsp;University of Campinas, Brazil.<br /><br /> Akshay&nbsp;Gadi&nbsp;Patil, a new Ph.D. student starting in September 2016, who obtained his&nbsp;M.Tech&nbsp;from&nbsp; Indian Institute of Technology&nbsp;Gandhinagar, and his B.Eng.&nbsp;from the&nbsp;P.E.S Institute of Technology (now PES University).<br /><br /> Rakesh&nbsp;Shrestha, a new M.Sc. student starting in September 2016, who obtained his B.Sc. from Bangladash.<br /><br /> Feitong Tan, a new Ph.D. student starting in September 2016, who obtained his M.Sc. from Chengdu, China.<br /><br /> Sicong Tang, a new Ph.D. starting in September 2016, who obtained his M.Sc. from&nbsp;Northwestern Polytechnical University in China.<br /><br /> Zili&nbsp;Yi, a visiting PhD student starting in September 2016, who obtained his&nbsp;M.E. from&nbsp;University&nbsp;of Chinese Academy of Sciences,&nbsp;China and his BSc from&nbsp;Nanjing&nbsp;University,&nbsp;China.
  highlight: 0
  image: 9new.png

- date: August 5, 2016
  headline: Richard keynote talk at CCCG'16
  text: GrUVi faculty Richard Zhang was invited to give a keynote talk at the 2016 Canadian Conference on Computational Geometry (CCCG). His talk is titled "New Geometry Problems in Computational Design and Fabrication".
  highlight: 0
  image: Richard.jpeg

- date: July 24, 2016
  headline: GrUVi co-authors three SIG papers
  text: The three papers are&#58; <a href="http://vcc.szu.edu.cn/research/2016/Icon2/">Learning How Objects Function via Co-Analysis of Interactions</a>, <a href="http://www.cs.sfu.ca/~haoz/pubs/zhao_sig16_fermat.pdf">Connected Fermat Spirals for Layered Fabrication</a>, and <a href="http://www.cs.sfu.ca/~haoz/pubs/zou_sig16_calli.pdf">Legible Compact Calligrams</a>.&nbsp;The latter paper was led by&nbsp;<a href="http://changqingzou.weebly.com/">Changqing Zou</a>,&nbsp;a postdoc co-supervised by Ping and Richard, who just&nbsp;had his first paper accepted to SIGGRAPH. This work was&nbsp;a collaboration between SFU and UBC. Other collaborators on these papers include those from Carleton University, Shenzhen University, Purdue University, Shandong University, Tel-Aviv University, the Interdisciplinary Center (IDC, Israel),&nbsp;Toyota Technical Institute (TTI, USA), Dalian University of Technology,&nbsp;and University of Southern California.
  highlight: 0
  image: SIG16.png

- date: May 19, 2016
  headline: Richard wins SFU service award
  text: Richard Zhang completed his four-year term as the Graduate Program Director at the School of Computing Science on April 30, 2016. With his services and contributions, he was selected as the sole winner of the SFU Dean of Graduate Studies Award of Excellence in Leadership in 2016. Each award consists of a prize of a $1,000 graduate student travel award that will be disbursed in the following academic year to a graduate student of the award recipient™s choice to attend a conference to present a paper.
  highlight: 0
  image: SFUserviceAward.jpg

- date: March 14, 2016
  headline: Ibraheem wins Alain Fournier Award
  text: This award is given to the top computer graphics Ph.D. dissertation defended in a Canadian university in a given year and will be officially announced at Graphics Interface '16. The award recognizes the strength and quality of Ibraheem's contributions in his dissertation titled "Topology Varying Shape Matching and Modelling".
  highlight: 0
  image: ibrahimAlain.png
